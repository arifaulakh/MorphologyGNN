{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuron import h, gui\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from morphopy.computation import file_manager as fm\n",
    "from morphopy.neurontree import NeuronTree as nt\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0f730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOUWENS_DIR = \"/external/rprshnas01/netdata_kcni/stlab/Public/AIBS_patchseq_2020/mouse/morphology/download.brainlib.org+8811/biccn/zeng/pseq/morph/200526/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb526722-5f23-4211-9b3d-318b7b420d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_from_file(filename):\n",
    "    parts = filename.split(\"/\")\n",
    "    extracted_number = parts[-1].split(\"_\")[0]\n",
    "\n",
    "    return extracted_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83875dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_graph(filename):\n",
    "    try:\n",
    "        N = fm.load_swc_file(filename)\n",
    "        _id = extract_id_from_file(filename)\n",
    "        return (int(_id), N, N.get_graph())\n",
    "    except ValueError:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6121849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(filename):\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    if match:\n",
    "        number = match.group()\n",
    "        return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33fcce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graphs(directory):\n",
    "    file_list = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\"_transformed.swc\"):\n",
    "            file_list.append(os.path.join(directory, file))\n",
    "            \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e0157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_graphs(GOUWENS_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee74f821-34e9-4758-b3f7-1408980373cd",
   "metadata": {},
   "source": [
    "# Load Gouwens Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ea8c8f-b30a-4757-9369-42bfa44427ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('/nethome/kcni/aaulakh/morphology/metadata_gouwens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f75f46d-8aeb-4770-b00f-3f5da1fc22ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sample_id', 'project', 'cell_specimen_id',\n",
       "       'cell_specimen_name', 'hemisphere', 'structure', 'donor_id',\n",
       "       'donor_name', 'biological_sex', 'age', 'full_genotype', 'dendrite_type',\n",
       "       'apical_dendrite_status', 'neuron_reconstruction_type',\n",
       "       'cell_soma_normalized_depth', 'ephys_session_id',\n",
       "       'transcriptomics_batch', 'corresponding_AIT2.3.1_ID',\n",
       "       'corresponding_AIT2.3.1_alias', 'major_type', 'contam_type',\n",
       "       'quality_score', 'Microglia', 'cluster_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44b9cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corresponding_AIT2.3.1_alias\n",
       "Sst Calb2         321\n",
       "Sst Hpse          310\n",
       "Pvalb Reln        285\n",
       "Sst Rxfp1         239\n",
       "Lamp5 Lsp1        195\n",
       "Pvalb Sema3e      176\n",
       "Pvalb Tpbg        176\n",
       "Sncg Vip          174\n",
       " NA               165\n",
       "Vip Crispld2      155\n",
       "Lamp5 Plch2       150\n",
       "Sst Esm1          146\n",
       "Sst Tac2          141\n",
       "Sst Chodl         132\n",
       "Vip Lmo1          130\n",
       "Vip Ptprt         128\n",
       "Sst Tac1          117\n",
       "Sst Crhr2         116\n",
       "Vip Pygm           99\n",
       "Sst Myh8           79\n",
       "Lamp5 Ntn1         73\n",
       "Sst Mme            68\n",
       "Pvalb Akr1c18      64\n",
       "Vip Chat           63\n",
       "Pvalb Th           55\n",
       "Vip Col15a1        54\n",
       "Sncg Gpr50         49\n",
       "Sst Nts            47\n",
       "Pvalb Gabrg1       46\n",
       "Vip Rspo4          43\n",
       "Sst Crh            42\n",
       "Pvalb Calb1        38\n",
       "Sst Nr2f2          37\n",
       "Vip Arhgap36       36\n",
       "Serpinf1 Aqp5      34\n",
       "Vip Lect1          30\n",
       "Sst Chrna2         29\n",
       "Lamp5 Fam19a1      28\n",
       "Pvalb Gpr149       24\n",
       "Pvalb Vipr2        24\n",
       "Vip Igfbp4         20\n",
       "Vip Gpc3           20\n",
       "Lamp5 Lhx6         19\n",
       "Serpinf1 Clrn1     13\n",
       "Sncg Slc17a8       12\n",
       "Lamp5 Krt73        12\n",
       "Vip Rspo1          11\n",
       "Vip Igfbp6          8\n",
       "Meis2 Adamts19      1\n",
       "L2 3                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['corresponding_AIT2.3.1_alias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c7edf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the corresponding labels\n",
    "encoded_labels = label_encoder.fit_transform(metadata_df['corresponding_AIT2.3.1_alias'])\n",
    "\n",
    "# Store the encoded labels back into the DataFrame\n",
    "metadata_df['encoded_labels'] = encoded_labels\n",
    "\n",
    "# Create a mapping dictionary of original labels to encoded values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db655877-23db-42a6-aa22-9a4591787af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_object(df, _id, g, neuron_tree):\n",
    "    data = from_networkx(g, group_node_attrs=neuron_tree.get_node_attribute_names(), group_edge_attrs=neuron_tree.get_edge_attribute_names())\n",
    "    \n",
    "    subclass_label = df.loc[df['cell_specimen_id'] == _id, 'encoded_labels'].values[0]\n",
    "    subclass_label = np.array([subclass_label], dtype=np.int64)\n",
    "    data.y = torch.from_numpy(subclass_label)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f00cc84-2cf4-47a6-add6-1700ac0b6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_objects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b04b2ba-5b55-42de-8866-8aeb49176f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samples:\n",
    "    g_info = extract_graph(s)\n",
    "    if g_info != -1:\n",
    "        _id = g_info[0]\n",
    "        neuron_tree = g_info[1]\n",
    "        g = g_info[2]\n",
    "        if len(list(nx.weakly_connected_components(g))) == 1:\n",
    "            try:\n",
    "                data_object = create_pytorch_object(metadata_df, _id, g, neuron_tree)\n",
    "                data_objects.append(data_object)\n",
    "            except ValueError:\n",
    "                disconnected_nodes = [node for node in g.nodes() if not nx.node_connected_component(g, node)]\n",
    "                print(f\"Skipping graph {_id} due to disconnected nodes: {disconnected_nodes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7372683c-6bae-4161-889c-13c4eb2cf0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0f38b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphologyDataset(Dataset):\n",
    "    def __init__(self, data_objects, transform=None):\n",
    "        super().__init__(root=None, transform=transform)\n",
    "        self.data_objects = data_objects\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_objects)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_objects[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2eae377",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MorphologyDataset(data_objects, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38f349a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MorphologyDataset(537):\n",
      "====================\n",
      "Number of graphs: 537\n",
      "Number of features: 5\n",
      "Number of classes: 50\n",
      "\n",
      "Data(edge_index=[2, 5913], x=[5914, 5], edge_attr=[5913, 2], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 5914\n",
      "Number of edges: 5913\n",
      "Average node degree: 1.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03ccd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:376]\n",
    "test_dataset = dataset[376:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37f504d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 328025], x=[328057, 5], edge_attr=[328025, 2], y=[32], batch=[328057], ptr=[33])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 328453], x=[328485, 5], edge_attr=[328453, 2], y=[32], batch=[328485], ptr=[33])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 391125], x=[391157, 5], edge_attr=[391125, 2], y=[32], batch=[391157], ptr=[33])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 396365], x=[396397, 5], edge_attr=[396365, 2], y=[32], batch=[396397], ptr=[33])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 340272], x=[340304, 5], edge_attr=[340272, 2], y=[32], batch=[340304], ptr=[33])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 306125], x=[306157, 5], edge_attr=[306125, 2], y=[32], batch=[306157], ptr=[33])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 344876], x=[344908, 5], edge_attr=[344876, 2], y=[32], batch=[344908], ptr=[33])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 379935], x=[379967, 5], edge_attr=[379935, 2], y=[32], batch=[379967], ptr=[33])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 351673], x=[351705, 5], edge_attr=[351673, 2], y=[32], batch=[351705], ptr=[33])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 304339], x=[304371, 5], edge_attr=[304339, 2], y=[32], batch=[304371], ptr=[33])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 326704], x=[326736, 5], edge_attr=[326704, 2], y=[32], batch=[326736], ptr=[33])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 24\n",
      "DataBatch(edge_index=[2, 262515], x=[262539, 5], edge_attr=[262515, 2], y=[24], batch=[262539], ptr=[25])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2d6461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3b0c5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 5913], x=[5914, 5], edge_attr=[5913, 2], y=[1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8392acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "929bb883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.0372, Test Acc: 0.0683\n",
      "Epoch: 002, Train Acc: 0.1090, Test Acc: 0.1366\n",
      "Epoch: 003, Train Acc: 0.1330, Test Acc: 0.1180\n",
      "Epoch: 004, Train Acc: 0.1543, Test Acc: 0.2112\n",
      "Epoch: 005, Train Acc: 0.1569, Test Acc: 0.1553\n",
      "Epoch: 006, Train Acc: 0.2074, Test Acc: 0.2050\n",
      "Epoch: 007, Train Acc: 0.1835, Test Acc: 0.2236\n",
      "Epoch: 008, Train Acc: 0.2154, Test Acc: 0.2360\n",
      "Epoch: 009, Train Acc: 0.2340, Test Acc: 0.2112\n",
      "Epoch: 010, Train Acc: 0.2154, Test Acc: 0.2298\n",
      "Epoch: 011, Train Acc: 0.2287, Test Acc: 0.2112\n",
      "Epoch: 012, Train Acc: 0.2340, Test Acc: 0.2050\n",
      "Epoch: 013, Train Acc: 0.2527, Test Acc: 0.2236\n",
      "Epoch: 014, Train Acc: 0.2660, Test Acc: 0.2174\n",
      "Epoch: 015, Train Acc: 0.2527, Test Acc: 0.2236\n",
      "Epoch: 016, Train Acc: 0.2553, Test Acc: 0.1739\n",
      "Epoch: 017, Train Acc: 0.2340, Test Acc: 0.2422\n",
      "Epoch: 018, Train Acc: 0.2128, Test Acc: 0.1988\n",
      "Epoch: 019, Train Acc: 0.2527, Test Acc: 0.2360\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "model.double()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.double()\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
