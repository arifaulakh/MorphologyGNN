{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from morphopy.computation import file_manager as fm\n",
    "from morphopy.neurontree import NeuronTree as nt\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d1627",
   "metadata": {},
   "source": [
    "## Directory for Gouwens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOUWENS_DIR = \"/external/rprshnas01/netdata_kcni/stlab/Public/AIBS_patchseq_2020/mouse/morphology/download.brainlib.org+8811/biccn/zeng/pseq/morph/200526/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89f740",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_from_file(filename):\n",
    "    parts = filename.split(\"/\")\n",
    "    extracted_number = parts[-1].split(\"_\")[0]\n",
    "\n",
    "    return extracted_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_graph(filename):\n",
    "    try:\n",
    "        N = fm.load_swc_file(filename)\n",
    "        _id = extract_id_from_file(filename)\n",
    "        return (int(_id), N, N.get_graph())\n",
    "    except ValueError:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(filename):\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    if match:\n",
    "        number = match.group()\n",
    "        return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graphs(directory):\n",
    "    file_list = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\"_transformed.swc\"):\n",
    "            file_list.append(os.path.join(directory, file))\n",
    "            \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_graphs(GOUWENS_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Gouwens Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('/nethome/kcni/aaulakh/morphology/metadata_gouwens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['corresponding_AIT2.3.1_alias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['cluster_label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df85360f",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the corresponding labels\n",
    "encoded_labels = label_encoder.fit_transform(metadata_df['cluster_label'])\n",
    "\n",
    "# Store the encoded labels back into the DataFrame\n",
    "metadata_df['encoded_labels'] = encoded_labels\n",
    "\n",
    "# Create a mapping dictionary of original labels to encoded values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_object(df, _id, g, neuron_tree):\n",
    "    data = from_networkx(g, group_node_attrs=neuron_tree.get_node_attribute_names(), group_edge_attrs=neuron_tree.get_edge_attribute_names())\n",
    "    \n",
    "    subclass_label = df.loc[df['cell_specimen_id'] == _id, 'encoded_labels'].values[0]\n",
    "    subclass_label = np.array([subclass_label], dtype=np.int64)\n",
    "    data.y = torch.from_numpy(subclass_label)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_objects = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d827ec",
   "metadata": {},
   "source": [
    "### Create Graph Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samples:\n",
    "    g_info = extract_graph(s)\n",
    "    if g_info != -1:\n",
    "        _id = g_info[0]\n",
    "        neuron_tree = g_info[1]\n",
    "        g = g_info[2]\n",
    "        if len(list(nx.weakly_connected_components(g))) == 1:\n",
    "            try:\n",
    "                data_object = create_pytorch_object(metadata_df, _id, g, neuron_tree)\n",
    "                data_objects.append(data_object)\n",
    "            except ValueError:\n",
    "                disconnected_nodes = [node for node in g.nodes() if not nx.node_connected_component(g, node)]\n",
    "                print(f\"Skipping graph {_id} due to disconnected nodes: {disconnected_nodes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93c0cb",
   "metadata": {},
   "source": [
    "### Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphologyDataset(Dataset):\n",
    "    def __init__(self, data_objects, transform=None):\n",
    "        super().__init__(root=None, transform=transform)\n",
    "        self.data_objects = data_objects\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_objects)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_objects[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MorphologyDataset(data_objects, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, '/nethome/kcni/aaulakh/morphology/gouwens_pyg_clusters_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c34bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('/nethome/kcni/aaulakh/morphology/gouwens_pyg_clusters_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:376]\n",
    "test_dataset = dataset[376:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ee72c",
   "metadata": {},
   "source": [
    "### Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267f8cf",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, dropout_rate=0.5, l2_regularization=0.01):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.l2_regularization = l2_regularization\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def l2_loss(self):\n",
    "        l2_loss = 0\n",
    "        for param in self.parameters():\n",
    "            l2_loss += torch.norm(param, p=2)\n",
    "        return l2_loss\n",
    "\n",
    "    def loss(self, pred, target):\n",
    "        return F.cross_entropy(pred, target) + self.l2_regularization * self.l2_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543dbf1",
   "metadata": {},
   "source": [
    "### Set-up GPU access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ffc98",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64).to(device)\n",
    "model.double()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "def train():\n",
    "    model.double()\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    epochs.append(epoch)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ba1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs, test_accuracies, label='Test Accuracy')\n",
    "plt.title('Train and Test Accuracy vs. Epochs using Clusters')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('/nethome/kcni/aaulakh/morphology/500_epochs_gnn_clusters.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
